{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa5466d8-82ed-4512-99ad-02e5e05a4c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbbf3642-4efd-4d30-abc7-9c52b849ffeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "talents=pd.read_csv('C:/Users/M-ODE/Desktop/Apziva/projects/3rd Project/potential_talents/data/potential_talents_CSV.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28cbeea4-ed0c-4b47-84c8-ef9fc943cde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "talents_df=talents.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fa8884f-cb32-4349-ac76-cfebd996b22f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>job_title</th>\n",
       "      <th>location</th>\n",
       "      <th>connection</th>\n",
       "      <th>fit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2019 C.T. Bauer College of Business Graduate (...</td>\n",
       "      <td>Houston, Texas</td>\n",
       "      <td>85</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Native English Teacher at EPIK (English Progra...</td>\n",
       "      <td>Kanada</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Aspiring Human Resources Professional</td>\n",
       "      <td>Raleigh-Durham, North Carolina Area</td>\n",
       "      <td>44</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>People Development Coordinator at Ryan</td>\n",
       "      <td>Denton, Texas</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Advisory Board Member at Celal Bayar University</td>\n",
       "      <td>İzmir, Türkiye</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100</td>\n",
       "      <td>Aspiring Human Resources Manager | Graduating ...</td>\n",
       "      <td>Cape Girardeau, Missouri</td>\n",
       "      <td>103</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>101</td>\n",
       "      <td>Human Resources Generalist at Loparex</td>\n",
       "      <td>Raleigh-Durham, North Carolina Area</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>102</td>\n",
       "      <td>Business Intelligence and Analytics at Travelers</td>\n",
       "      <td>Greater New York City Area</td>\n",
       "      <td>49</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>103</td>\n",
       "      <td>Always set them up for Success</td>\n",
       "      <td>Greater Los Angeles Area</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>104</td>\n",
       "      <td>Director Of Administration at Excellence Logging</td>\n",
       "      <td>Katy, Texas</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>104 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                          job_title  \\\n",
       "0      1  2019 C.T. Bauer College of Business Graduate (...   \n",
       "1      2  Native English Teacher at EPIK (English Progra...   \n",
       "2      3              Aspiring Human Resources Professional   \n",
       "3      4             People Development Coordinator at Ryan   \n",
       "4      5    Advisory Board Member at Celal Bayar University   \n",
       "..   ...                                                ...   \n",
       "99   100  Aspiring Human Resources Manager | Graduating ...   \n",
       "100  101              Human Resources Generalist at Loparex   \n",
       "101  102   Business Intelligence and Analytics at Travelers   \n",
       "102  103                     Always set them up for Success   \n",
       "103  104   Director Of Administration at Excellence Logging   \n",
       "\n",
       "                                location connection  fit  \n",
       "0                         Houston, Texas         85  NaN  \n",
       "1                                 Kanada      500+   NaN  \n",
       "2    Raleigh-Durham, North Carolina Area         44  NaN  \n",
       "3                          Denton, Texas      500+   NaN  \n",
       "4                         İzmir, Türkiye      500+   NaN  \n",
       "..                                   ...        ...  ...  \n",
       "99              Cape Girardeau, Missouri        103  NaN  \n",
       "100  Raleigh-Durham, North Carolina Area      500+   NaN  \n",
       "101           Greater New York City Area         49  NaN  \n",
       "102             Greater Los Angeles Area      500+   NaN  \n",
       "103                          Katy, Texas      500+   NaN  \n",
       "\n",
       "[104 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "talents_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "925d9531-7c1c-4c43-8d18-9b781eae7d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 104 entries, 0 to 103\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   id          104 non-null    int64  \n",
      " 1   job_title   104 non-null    object \n",
      " 2   location    104 non-null    object \n",
      " 3   connection  104 non-null    object \n",
      " 4   fit         0 non-null      float64\n",
      "dtypes: float64(1), int64(1), object(3)\n",
      "memory usage: 4.2+ KB\n"
     ]
    }
   ],
   "source": [
    "talents_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71f63f93-15b4-43a3-9aab-269064f21f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of rows 104\n"
     ]
    }
   ],
   "source": [
    "print('Total number of rows',len(talents_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8582230b-0509-4177-9e5c-a964c98c12bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id              0\n",
       "job_title       0\n",
       "location        0\n",
       "connection      0\n",
       "fit           104\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check missing values\n",
    "talents_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98a3e8d-58f2-4bff-ab2b-086aae1b54ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551789ad-0c9a-4a7c-83e2-cb17a28fcac9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3418d84f-cc22-4cea-b813-85eddc155689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing ; for old models/ Not advanced \n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "stemmer = PorterStemmer()\n",
    "lemma = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(review):\n",
    "    # Remove non-alphabet characters, convert to lowercase, and tokenize\n",
    "    review = word_tokenize(re.sub('[^a-zA-Z]', ' ', review.lower()))\n",
    "    # Remove stopwords\n",
    "    review = [w for w in review if w not in stop_words]\n",
    "    # Apply stemming \n",
    "    # review = [stemmer.stem(w) for w in review]\n",
    "    # Apply lemmatization\n",
    "    review = [lemma.lemmatize(w, pos='v') for w in review]\n",
    "    # Join the processed words back into a string\n",
    "    review = ' '.join(review)\n",
    "    return review\n",
    "\n",
    "talents_df['job_title_clean'] = talents_df['job_title'].apply(preprocess_text)\n",
    "talents_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee723e57-f6e7-4a27-928f-95022f36cfbc",
   "metadata": {},
   "source": [
    "!pip install transformers \n",
    "!pip install torch "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c805030-17a7-4905-a6e7-c0a28a5df48f",
   "metadata": {},
   "source": [
    "## TF-IDF  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b55c100-d10e-4f55-bee2-4e4a88cb80d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>job_title</th>\n",
       "      <th>location</th>\n",
       "      <th>connection</th>\n",
       "      <th>fit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>73</td>\n",
       "      <td>Aspiring Human Resources Manager, seeking inte...</td>\n",
       "      <td>Houston, Texas Area</td>\n",
       "      <td>7</td>\n",
       "      <td>0.553403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>46</td>\n",
       "      <td>Aspiring Human Resources Professional</td>\n",
       "      <td>Raleigh-Durham, North Carolina Area</td>\n",
       "      <td>44</td>\n",
       "      <td>0.539892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>Aspiring Human Resources Professional</td>\n",
       "      <td>Raleigh-Durham, North Carolina Area</td>\n",
       "      <td>44</td>\n",
       "      <td>0.539892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Aspiring Human Resources Professional</td>\n",
       "      <td>Raleigh-Durham, North Carolina Area</td>\n",
       "      <td>44</td>\n",
       "      <td>0.539892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>58</td>\n",
       "      <td>Aspiring Human Resources Professional</td>\n",
       "      <td>Raleigh-Durham, North Carolina Area</td>\n",
       "      <td>44</td>\n",
       "      <td>0.539892</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                                          job_title  \\\n",
       "72  73  Aspiring Human Resources Manager, seeking inte...   \n",
       "45  46              Aspiring Human Resources Professional   \n",
       "32  33              Aspiring Human Resources Professional   \n",
       "16  17              Aspiring Human Resources Professional   \n",
       "57  58              Aspiring Human Resources Professional   \n",
       "\n",
       "                               location connection       fit  \n",
       "72                  Houston, Texas Area          7  0.553403  \n",
       "45  Raleigh-Durham, North Carolina Area         44  0.539892  \n",
       "32  Raleigh-Durham, North Carolina Area         44  0.539892  \n",
       "16  Raleigh-Durham, North Carolina Area         44  0.539892  \n",
       "57  Raleigh-Durham, North Carolina Area         44  0.539892  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "data = pd.read_csv('C:/Users/M-ODE/Desktop/Apziva/projects/3rd Project/potential_talents/data/potential_talents_CSV.csv')\n",
    "\n",
    "# Keywords for ranking\n",
    "keywords = [\"Aspiring human resources\", \"seeking human resources\"]\n",
    "\n",
    "# Combine the job titles into a list for TF-IDF processing\n",
    "job_titles = data['job_title'].tolist()\n",
    "\n",
    "# Create a TF-IDF vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(job_titles)\n",
    "\n",
    "# Calculate cosine similarities for each keyword\n",
    "keyword_similarities = []\n",
    "for keyword in keywords:\n",
    "    keyword_tfidf = tfidf_vectorizer.transform([keyword])\n",
    "    similarities = cosine_similarity(keyword_tfidf, tfidf_matrix)\n",
    "    keyword_similarities.append(similarities[0])\n",
    "\n",
    "# Calculate the average similarity for each job title based on all keywords\n",
    "combined_scores = np.mean(keyword_similarities, axis=0)\n",
    "data['fit'] = combined_scores\n",
    "# Sort the DataFrame by similarity scores (higher scores indicate better matches)\n",
    "ranked_data = data.sort_values(by='fit', ascending=False)\n",
    "\n",
    "ranked_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d63fe01-d84c-48e9-bb8a-1ef61f612772",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce1f674-bfca-4332-a385-2eed3958c3b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8364615e-aeb3-4cf6-b0cd-82ee8fbd81b4",
   "metadata": {},
   "source": [
    "## #Glovec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13946e67-829b-40f9-bf91-a0064cd11055",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\M-ODE\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "503f842a-cfd6-4fea-a42c-bcc91e45ce97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Glove Model\n",
      "400001 words loaded!\n"
     ]
    }
   ],
   "source": [
    "# Load DataFrame containing job titles\n",
    "data = pd.read_csv('C:/Users/M-ODE/Desktop/Apziva/projects/3rd Project/potential_talents/data/potential_talents_CSV.csv')\n",
    "\n",
    "# Tokenize the keywords\n",
    "keywords = [\"Aspiring human resources\", \"seeking human resources\"]\n",
    "tokenized_keywords = [word_tokenize(keyword.lower()) for keyword in keywords]\n",
    "\n",
    "\n",
    "#Load Glove model\n",
    "def load_glove_model(File):\n",
    "    print(\"Loading Glove Model\")\n",
    "    glove_model = {}\n",
    "    with open(File,'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            split_line = line.split()\n",
    "            word = split_line[0]\n",
    "            embedding = np.array(split_line[1:], dtype=np.float64)\n",
    "            glove_model[word] = embedding\n",
    "    print(f\"{len(glove_model)} words loaded!\")\n",
    "    return glove_model\n",
    "embedding_model = load_glove_model('glove.6B.300d.txt')\n",
    "\n",
    "# Process job_title column using NLTK \n",
    "tokenized_titles = [word_tokenize(title.lower()) for title in data['job_title']]\n",
    "\n",
    "# Calculate the mean embedding for each keyword\n",
    "keyword_embeddings = []\n",
    "for keyword_tokens in tokenized_keywords:\n",
    "    keyword_embedding = np.mean([embedding_model.get(word, np.zeros_like(embedding_model[\"a\"])) for word in keyword_tokens], axis=0)\n",
    "    keyword_embeddings.append(tuple(keyword_embedding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c178d386-c8e8-4546-b456-9f0c52e60e38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>job_title</th>\n",
       "      <th>location</th>\n",
       "      <th>connection</th>\n",
       "      <th>fit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Seeking Human Resources Opportunities</td>\n",
       "      <td>Chicago, Illinois</td>\n",
       "      <td>390</td>\n",
       "      <td>0.899883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>Seeking Human Resources Opportunities</td>\n",
       "      <td>Chicago, Illinois</td>\n",
       "      <td>390</td>\n",
       "      <td>0.899883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>Aspiring Human Resources Specialist</td>\n",
       "      <td>Greater New York City Area</td>\n",
       "      <td>1</td>\n",
       "      <td>0.888238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Aspiring Human Resources Specialist</td>\n",
       "      <td>Greater New York City Area</td>\n",
       "      <td>1</td>\n",
       "      <td>0.888238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>36</td>\n",
       "      <td>Aspiring Human Resources Specialist</td>\n",
       "      <td>Greater New York City Area</td>\n",
       "      <td>1</td>\n",
       "      <td>0.888238</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                              job_title                    location  \\\n",
       "27  28  Seeking Human Resources Opportunities           Chicago, Illinois   \n",
       "29  30  Seeking Human Resources Opportunities           Chicago, Illinois   \n",
       "23  24    Aspiring Human Resources Specialist  Greater New York City Area   \n",
       "5    6    Aspiring Human Resources Specialist  Greater New York City Area   \n",
       "35  36    Aspiring Human Resources Specialist  Greater New York City Area   \n",
       "\n",
       "   connection       fit  \n",
       "27        390  0.899883  \n",
       "29        390  0.899883  \n",
       "23          1  0.888238  \n",
       "5           1  0.888238  \n",
       "35          1  0.888238  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the embeddings for each candidate's job title\n",
    "candidate_embeddings = []\n",
    "for candidate_title in tokenized_titles:\n",
    "    embedding_sum = np.zeros_like(embedding_model[\"a\"])\n",
    "    word_count = 0\n",
    "    for word in candidate_title:\n",
    "        if word in embedding_model:\n",
    "            embedding_sum += embedding_model[word]\n",
    "            word_count += 1\n",
    "    if word_count > 0:\n",
    "        candidate_embedding = embedding_sum / word_count\n",
    "    else:\n",
    "        candidate_embedding = np.zeros_like(embedding_model[\"a\"])\n",
    "    candidate_embeddings.append(candidate_embedding)\n",
    "    \n",
    "    \n",
    "# Calculate similarity for each candidate\n",
    "similarity_scores = []\n",
    "for keyword_embedding in keyword_embeddings:\n",
    "    candidate_similarities = []\n",
    "    for candidate_embedding in candidate_embeddings:\n",
    "        similarity = cosine_similarity([candidate_embedding], [keyword_embedding])[0, 0]\n",
    "        candidate_similarities.append(similarity)\n",
    "    similarity_scores.append(candidate_similarities)\n",
    "    \n",
    "\n",
    "# Combine the similarity scores for all keywords\n",
    "combined_scores = np.mean(similarity_scores, axis=0)\n",
    "\n",
    "# Check if the length of combined_scores matches the DataFrame length\n",
    "if len(combined_scores) != len(talents_df):\n",
    "    raise ValueError(\"Length of 'combined_scores' does not match the length of the DataFrame.\")\n",
    "\n",
    "# Update the 'fit' column in the DataFrame\n",
    "data['fit'] = combined_scores\n",
    "\n",
    "\n",
    "# Combine the similarity scores for all keywords\n",
    "combined_scores = np.mean(similarity_scores, axis=0)\n",
    "\n",
    "# Update the 'fit' column in the DataFrame\n",
    "data['fit'] = combined_scores\n",
    "\n",
    "# Sort the DataFrame based on the initial fit scores\n",
    "data=data.sort_values(by='fit', ascending=False)\n",
    "\n",
    "# View the resulting DataFrame\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc0b5b7-53e9-44a7-973d-96fbe4b7d263",
   "metadata": {},
   "source": [
    "## Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6403c890-2493-46ac-af3c-7dc976dd9185",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>job_title</th>\n",
       "      <th>location</th>\n",
       "      <th>connection</th>\n",
       "      <th>fit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>Seeking Human Resources Opportunities</td>\n",
       "      <td>Chicago, Illinois</td>\n",
       "      <td>390</td>\n",
       "      <td>0.879002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Seeking Human Resources Opportunities</td>\n",
       "      <td>Chicago, Illinois</td>\n",
       "      <td>390</td>\n",
       "      <td>0.879002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99</td>\n",
       "      <td>Seeking Human Resources Position</td>\n",
       "      <td>Las Vegas, Nevada Area</td>\n",
       "      <td>48</td>\n",
       "      <td>0.872550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Aspiring Human Resources Professional</td>\n",
       "      <td>Raleigh-Durham, North Carolina Area</td>\n",
       "      <td>44</td>\n",
       "      <td>0.848709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>46</td>\n",
       "      <td>Aspiring Human Resources Professional</td>\n",
       "      <td>Raleigh-Durham, North Carolina Area</td>\n",
       "      <td>44</td>\n",
       "      <td>0.848709</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                              job_title  \\\n",
       "29  30  Seeking Human Resources Opportunities   \n",
       "27  28  Seeking Human Resources Opportunities   \n",
       "98  99       Seeking Human Resources Position   \n",
       "2    3  Aspiring Human Resources Professional   \n",
       "45  46  Aspiring Human Resources Professional   \n",
       "\n",
       "                               location connection       fit  \n",
       "29                    Chicago, Illinois        390  0.879002  \n",
       "27                    Chicago, Illinois        390  0.879002  \n",
       "98               Las Vegas, Nevada Area         48  0.872550  \n",
       "2   Raleigh-Durham, North Carolina Area         44  0.848709  \n",
       "45  Raleigh-Durham, North Carolina Area         44  0.848709  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "\n",
    "# Load a pre-trained BERT model and tokenizer\n",
    "model_name = \"bert-base-uncased\"\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertModel.from_pretrained(model_name)\n",
    "\n",
    "# Load DataFrame containing job titles\n",
    "data = pd.read_csv('C:/Users/M-ODE/Desktop/Apziva/projects/3rd Project/potential_talents/data/potential_talents_CSV.csv')\n",
    "\n",
    "# Keywords for ranking\n",
    "keywords = [\"Aspiring human resources\", \"seeking human resources\"]\n",
    "\n",
    "# Create an empty list to store the similarity scores for each keyword\n",
    "keyword_similarities = []\n",
    "\n",
    "# Tokenize job titles and obtain their BERT embeddings\n",
    "job_title_tokens = [tokenizer(title, return_tensors=\"pt\") for title in data['job_title']]\n",
    "job_title_embeddings = []\n",
    "\n",
    "for keyword in keywords:\n",
    "    # Tokenize the current keyword and obtain its BERT embeddings\n",
    "    keyword_tokens = tokenizer(keyword, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        keyword_embeddings = model(**keyword_tokens).last_hidden_state.mean(dim=1)\n",
    "    \n",
    "    # Calculate cosine similarities between the current keyword and job title embeddings\n",
    "    similarities = []\n",
    "    with torch.no_grad():\n",
    "        for tokens in job_title_tokens:\n",
    "            embeddings = model(**tokens).last_hidden_state.mean(dim=1)\n",
    "            similarity = cosine_similarity(keyword_embeddings, embeddings).item()\n",
    "            similarities.append(similarity)\n",
    "    \n",
    "    # Append the similarity scores for the current keyword to the list\n",
    "    keyword_similarities.append(similarities)\n",
    "\n",
    "# Combine or average the similarity scores based on all keywords for each job title\n",
    "average_similarities = np.mean(keyword_similarities, axis=0)\n",
    "\n",
    "# Add the average similarity scores to the DataFrame for ranking\n",
    "data['fit'] = average_similarities\n",
    "\n",
    "# Sort the DataFrame by similarity scores (higher scores indicate better matches)\n",
    "ranked_data = data.sort_values(by='fit', ascending=False)\n",
    "\n",
    "ranked_data.head()\n",
    "# You can use ranked_data.tail() to view the bottom results as well\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6a5747-b952-4502-880b-79243f5b2de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title_tokens "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f7978e-7ff5-4fd7-bedc-d1a83c8c1fef",
   "metadata": {},
   "source": [
    "## Sbert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d84f22e-33dc-4310-8ceb-7b5998339c4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>job_title</th>\n",
       "      <th>location</th>\n",
       "      <th>connection</th>\n",
       "      <th>fit</th>\n",
       "      <th>similarity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>Seeking Human Resources Opportunities</td>\n",
       "      <td>Chicago, Illinois</td>\n",
       "      <td>390</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.901338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Seeking Human Resources Opportunities</td>\n",
       "      <td>Chicago, Illinois</td>\n",
       "      <td>390</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.901338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99</td>\n",
       "      <td>Seeking Human Resources Position</td>\n",
       "      <td>Las Vegas, Nevada Area</td>\n",
       "      <td>48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.873473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>Aspiring Human Resources Professional</td>\n",
       "      <td>Raleigh-Durham, North Carolina Area</td>\n",
       "      <td>44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.839355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Aspiring Human Resources Professional</td>\n",
       "      <td>Raleigh-Durham, North Carolina Area</td>\n",
       "      <td>44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.839355</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                              job_title  \\\n",
       "29  30  Seeking Human Resources Opportunities   \n",
       "27  28  Seeking Human Resources Opportunities   \n",
       "98  99       Seeking Human Resources Position   \n",
       "32  33  Aspiring Human Resources Professional   \n",
       "2    3  Aspiring Human Resources Professional   \n",
       "\n",
       "                               location connection  fit  similarity_score  \n",
       "29                    Chicago, Illinois        390  NaN          0.901338  \n",
       "27                    Chicago, Illinois        390  NaN          0.901338  \n",
       "98               Las Vegas, Nevada Area         48  NaN          0.873473  \n",
       "32  Raleigh-Durham, North Carolina Area         44  NaN          0.839355  \n",
       "2   Raleigh-Durham, North Carolina Area         44  NaN          0.839355  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# Load a pre-trained SBERT model\n",
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "\n",
    "# Load DataFrame containing job titles\n",
    "data = pd.read_csv('C:/Users/M-ODE/Desktop/Apziva/projects/3rd Project/potential_talents/data/potential_talents_CSV.csv')\n",
    "\n",
    "# Keywords for ranking\n",
    "keywords = [\"Aspiring human resources\", \"seeking human resources\"]\n",
    "\n",
    "# Create an empty list to store the similarity scores for each keyword\n",
    "keyword_similarities = []\n",
    "\n",
    "# Tokenize job titles and obtain their SBERT embeddings\n",
    "job_title_embeddings = model.encode(data['job_title'].tolist(), convert_to_tensor=True)\n",
    "\n",
    "for keyword in keywords:\n",
    "    # Tokenize the current keyword and obtain its SBERT embedding\n",
    "    keyword_embedding = model.encode(keyword, convert_to_tensor=True)\n",
    "    \n",
    "    # Calculate cosine similarities between the current keyword and job title embeddings\n",
    "    similarities = util.pytorch_cos_sim(keyword_embedding, job_title_embeddings)\n",
    "    \n",
    "    # Convert the PyTorch tensor to a NumPy array before appending\n",
    "    keyword_similarities.append(similarities.cpu().numpy())\n",
    "\n",
    "# Combine or average the similarity scores based on all keywords for each job title\n",
    "average_similarities = np.mean(keyword_similarities, axis=0)\n",
    "\n",
    "# Reshape the average_similarities array to (104,)\n",
    "average_similarities = average_similarities[0]\n",
    "\n",
    "# Add the similarity scores to the DataFrame for ranking\n",
    "data['fit'] = average_similarities.tolist()\n",
    "\n",
    "# Sort the DataFrame by similarity scores (higher scores indicate better matches)\n",
    "ranked_data = data.sort_values(by='fit', ascending=False)\n",
    "\n",
    "ranked_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a37035b-0dce-4b4a-b42a-944d5df8bd9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
